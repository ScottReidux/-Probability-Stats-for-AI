{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TAlkam/-Probability-Stats-for-AI/blob/main/CKD_data_prepration_(6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation and Decision Stump"
      ],
      "metadata": {
        "id": "eYMlMPXn1QBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Upload file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "1kXtqbDPX2dP",
        "outputId": "8454b2eb-0c3e-41b5-be74-575ed373c64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-160b2136-aab9-461b-847a-5b5936b5e677\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-160b2136-aab9-461b-847a-5b5936b5e677\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ckd-dataset-v2 (2).csv to ckd-dataset-v2 (2) (4).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to take:\n",
        "\n",
        "1. Importing Libraries:\n",
        "The necessary libraries and modules are imported. These include `numpy`, `pandas`, `train_test_split` from `sklearn.model_selection`, `LogisticRegression` from `sklearn.linear_model`, `confusion_matrix`, `accuracy_score` from `sklearn.metrics`, `SimpleImputer` from `sklearn.impute`, and `OneHotEncoder` from `sklearn.preprocessing`.\n",
        "\n",
        "2. Defining a Function:\n",
        "The function `process_column` is defined to handle the data preprocessing step. This function checks if a value in a column is 'discrete' or contains a '-', or is a float. It returns NaN for 'discrete', the average of the two numbers if the value contains a '-', and the float value if it's a float. If none of these conditions are met, it returns NaN.\n",
        "\n",
        "3. Loading the Dataset:\n",
        "The dataset is loaded from a CSV file using `pd.read_csv`.\n",
        "\n",
        "4. Data Preprocessing:\n",
        "The `process_column` function is applied to the necessary columns of the dataframe. The target column 'class' is converted to integer type, where 'ckd' is represented as 1 and 'notckd' as 0. Missing values in the dataframe are filled with the mean of the respective column. Then, categorical variables are one-hot encoded, and the original categorical columns are dropped from the dataframe.\n",
        "\n",
        "5. Splitting the Dataset:\n",
        "The dataset is split into features (X) and target (y). Then, it's further split into training and testing sets using `train_test_split` function.\n",
        "\n",
        "6. Data Imputation:\n",
        "A `SimpleImputer` object is created to fill any remaining missing values in the dataset with the mean of the respective column. This imputer is fit on the training data and then used to transform both training and testing data.\n",
        "\n",
        "7. Training the Model:\n",
        "A Logistic Regression model is trained using the imputed training data.\n",
        "\n",
        "8. Making Predictions:\n",
        "The model is used to make predictions on the test data.\n",
        "\n",
        "9. Evaluating the Model:\n",
        "The accuracy of the model is printed out, and a confusion matrix is displayed to evaluate the performance of the model.\n",
        "\n",
        "Note: This code is quite comprehensive and incorporates several good practices like handling missing values, converting data types, one-hot encoding categorical variables, and splitting the dataset into training and testing sets. It also makes use of logistic regression, a simple and commonly used machine learning algorithm for binary classification problems."
      ],
      "metadata": {
        "id": "th1A-Nb_amxL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypertension (htn)**"
      ],
      "metadata": {
        "id": "zBSBCE1z9pK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data into a pandas DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assume that 'df' is your DataFrame, 'htn' is the feature column, and 'classification' is the target column\n",
        "# Also assuming that 'classification' is a binary variable\n",
        "\n",
        "# Handle missing values in 'htn' column by filling with the mode\n",
        "df['htn'] = df['htn'].fillna(df['htn'].mode()[0])\n",
        "\n",
        "# Encode 'htn' column to numerical values if it's categorical\n",
        "le = LabelEncoder()\n",
        "df['htn'] = le.fit_transform(df['htn'])\n",
        "\n",
        "X = df[['htn']]  # feature\n",
        "y = df['class']  # target\n",
        "\n",
        "# Split the dataset into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create an instance of DecisionTreeClassifier with max_depth = 1 (Decision Stump)\n",
        "clf = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cXQBD6rTHgk",
        "outputId": "de608250-def9-4c8e-df98-36c16dfab4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7377049180327869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diabetes Mellitus (dm)**"
      ],
      "metadata": {
        "id": "CnyDajie9yTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data into a pandas DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assume that 'df' is your DataFrame, 'dm' is the feature column, and 'classification' is the target column\n",
        "# Also assuming that 'classification' is a binary variable\n",
        "\n",
        "# Handle missing values in 'dm' column by filling with the mode\n",
        "df['dm'] = df['dm'].fillna(df['dm'].mode()[0])\n",
        "\n",
        "# Encode 'dm' column to numerical values if it's categorical\n",
        "le = LabelEncoder()\n",
        "df['dm'] = le.fit_transform(df['dm'])\n",
        "\n",
        "X = df[['dm']]  # feature\n",
        "y = df['class']  # target\n",
        "\n",
        "# Split the dataset into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create an instance of DecisionTreeClassifier with max_depth = 1 (Decision Stump)\n",
        "clf = DecisionTreeClassifier(max_depth=1, random_state=0)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O_1ANteSloL",
        "outputId": "06bd05d4-0a2b-4ec5-fccb-d8917f027a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7049180327868853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hemoglobin A1c (hemo)**"
      ],
      "metadata": {
        "id": "sSoC-O0Q9-nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Necessary imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "def process_column(col):\n",
        "    if 'discrete' in str(col):\n",
        "        return np.nan  # return NaN if 'discrete' is in column\n",
        "    if '-' in str(col):\n",
        "        low, high = map(float, str(col).split('-'))  # split on '-', convert to float\n",
        "        return (low + high) / 2  # return the average\n",
        "    else:\n",
        "        try:\n",
        "            return float(col)  # convert to float\n",
        "        except ValueError:\n",
        "            return np.nan  # if conversion to float fails, return NaN\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('ckd-dataset-v2 (2).csv')\n",
        "\n",
        "# Apply process_column function to necessary columns\n",
        "df['hemo'] = df['hemo'].apply(process_column)\n",
        "\n",
        "# Convert 'class' to integer type\n",
        "df['class'] = (df['class'] == 'ckd').astype(int)\n",
        "\n",
        "# Fill missing values with the mean of the respective column\n",
        "df['hemo'] = df['hemo'].fillna(df['hemo'].mean())\n",
        "\n",
        "# Split the dataset into features and target\n",
        "X = df[['hemo']]  # Select only the 'hemo' column as the feature\n",
        "y = df['class']\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use mean imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "# Fit on the training data\n",
        "imputer.fit(X_train)\n",
        "\n",
        "# Transform both training and testing data\n",
        "X_train = imputer.transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# Train the model using the imputed training data\n",
        "model = DecisionTreeClassifier(max_depth=1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print out the accuracy and confusion matrix\n",
        "print(f\"Accuracy: {round(accuracy_score(y_test, y_pred), 2)}\")\n",
        "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4iwtkoVp89B",
        "outputId": "d520923f-8825-4c5a-d217-6ea72eb5baa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.88\n",
            "Confusion Matrix:\n",
            "[[13  0]\n",
            " [ 5 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic regression"
      ],
      "metadata": {
        "id": "6KW0PCiz1m4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model from the `sklearn.linear_model` module.\n",
        "\n",
        "Here's a step-by-step breakdown of what the code is doing:\n",
        "\n",
        "1. `StandardScaler()`: This creates an instance of the StandardScaler class, which will be used to standardize the features by removing the mean and scaling to unit variance. This is often a good preprocessing step for many machine learning algorithms.\n",
        "\n",
        "2. `scaler.fit_transform(X_train)`: This fits the scaler to the training data and then transforms the training data. \"Fitting\" the scaler means that it learns the parameters (mean and standard deviation for standardization) of the training data.\n",
        "\n",
        "3. `scaler.transform(X_test)`: This uses the scaler that was fitted to the training data to transform the test data. It's important to note that the same scaler is used to transform both the training and test data to ensure that they are scaled in the same way.\n",
        "\n",
        "4. `LogisticRegression(max_iter=1000)`: This creates an instance of the LogisticRegression class. The `max_iter=1000` argument sets the maximum number of iterations for the solver to converge, which can be necessary for larger datasets.\n",
        "\n",
        "5. `model.fit(X_train, y_train)`: This fits the logistic regression model to the training data. \"Fitting\" the model means that it learns the relationship between the features (X_train) and the target (y_train).\n",
        "\n",
        "6. `model.predict(X_test)`: This uses the fitted model to make predictions on the test data.\n",
        "\n",
        "7. `accuracy_score(y_test, y_pred)`: This calculates the accuracy of the model by comparing the predicted values to the actual values.\n",
        "\n",
        "So, in summary, this code is using logistic regression to make predictions on the test data and then calculating the accuracy of those predictions."
      ],
      "metadata": {
        "id": "-mMpfxjI3y4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypertension (htn)**"
      ],
      "metadata": {
        "id": "ctrssxJA8n4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data into a pandas DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assume that 'df' is your DataFrame, 'htn' is the feature column, and 'classification' is the target column\n",
        "# Also assuming that 'classification' is a binary variable\n",
        "\n",
        "# Handle missing values in 'htn' column by filling with the mode\n",
        "df['htn'] = df['htn'].fillna(df['htn'].mode()[0])\n",
        "\n",
        "# Encode 'htn' column to numerical values if it's categorical\n",
        "le = LabelEncoder()\n",
        "df['htn'] = le.fit_transform(df['htn'])\n",
        "\n",
        "X = df[['htn']]  # feature\n",
        "y = df['class']  # target\n",
        "\n",
        "# Split the dataset into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create an instance of LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0sOK4gDQbUq",
        "outputId": "e852e644-5049-4446-a343-aa41f82eff29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7377049180327869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hemoglobin A1c (hemo)**"
      ],
      "metadata": {
        "id": "wgdhNKGb8vW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data into a pandas DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assume that 'df' is your DataFrame, 'hemo' is the feature column, and 'classification' is the target column\n",
        "# Also assuming that 'classification' is a binary variable\n",
        "\n",
        "# Handle missing values in 'hemo' column\n",
        "df['hemo'] = df['hemo'].fillna(df['hemo'].mean())\n",
        "\n",
        "X = df[['hemo']]  # feature\n",
        "y = df['class']  # target\n",
        "\n",
        "# Split the dataset into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create an instance of LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "\n",
        "# Train the model\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lr.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GOVigkAN2LV",
        "outputId": "77fbbd2c-917b-4745-e73d-d192f66e67e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8032786885245902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diabetes Mellitus (dm)**"
      ],
      "metadata": {
        "id": "IxLDfp0A9AtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Assuming 'dm' is your feature and 'classification' is your target\n",
        "X = df['dm'].values.reshape(-1,1)\n",
        "y = df['class']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Creating the Logistic Regression model\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "\n",
        "# Training the model\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: \", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y55XsVBC_KtL",
        "outputId": "cf56e306-5cc2-45c2-e34b-9d605a5e13ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix: \n",
            " [[13  0]\n",
            " [13 15]]\n",
            "Accuracy:  0.6829268292682927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "Y497m1g7fE9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script is about the Random Forest algorithm to a dataset for classification purposes, using the RandomForestClassifier class from the sklearn.ensemble module. Here are the key steps:\n",
        "\n",
        "RandomForestClassifier(n_estimators=100, random_state=42): This creates an instance of the RandomForestClassifier class with 100 trees in the forest (n_estimators=100) and a specified random state for reproducibility (random_state=42).\n",
        "\n",
        "rf.fit(X_train, y_train): This fits the Random Forest model to the training data. The model learns the relationship between the features (X_train) and the target (y_train) based on an ensemble of decision trees.\n",
        "\n",
        "rf.predict(X_test): This uses the fitted model to make predictions on the test data.\n",
        "\n",
        "accuracy_score(y_test, y_pred_rf): This computes the accuracy of the model by comparing the predicted values to the actual values.\n",
        "\n",
        "The Random Forest algorithm is a type of ensemble learning method, where multiple learning algorithms are used to obtain better predictive performance. In the case of Random Forest, it builds multiple decision trees and merges them together to get a more accurate and stable prediction."
      ],
      "metadata": {
        "id": "ovU6W44we5G5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TFLRPYfC9VtM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hemoglobin A1c (hemo)**"
      ],
      "metadata": {
        "id": "-eutEuEH-GB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data into a pandas DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assume that 'df' is your DataFrame, 'hemo' is the feature column, and 'classification' is the target column\n",
        "\n",
        "# Handle missing values in 'hemo' column by filling with the mean\n",
        "df['hemo'] = df['hemo'].fillna(df['hemo'].mean())\n",
        "\n",
        "X = df[['hemo']]  # feature\n",
        "y = df['class']  # target\n",
        "\n",
        "# Split the dataset into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create an instance of RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUcoWrXJUy9S",
        "outputId": "02ef393e-9a2f-418f-8ddd-1970cec5b55f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8852459016393442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypertension (htn)**"
      ],
      "metadata": {
        "id": "_pBF01-79gdu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load your data into a pandas DataFrame\n",
        "# df = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Assume that 'df' is your DataFrame, 'htn' is the feature column, and 'classification' is the target column\n",
        "# Also assuming that 'classification' is a binary variable\n",
        "\n",
        "# Handle missing values in 'htn' column by filling with the mode\n",
        "df['htn'] = df['htn'].fillna(df['htn'].mode()[0])\n",
        "\n",
        "# Encode 'htn' column to numerical values if it's categorical\n",
        "le = LabelEncoder()\n",
        "df['htn'] = le.fit_transform(df['htn'])\n",
        "\n",
        "X = df[['htn']]  # feature\n",
        "y = df['class']  # target\n",
        "\n",
        "# Split the dataset into 70% training data and 30% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# Create an instance of RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Print the accuracy of the model\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsV2NhH7UZqb",
        "outputId": "f0acb984-9ac9-4a63-870b-d0e83ed51277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7377049180327869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diabetes Mellitus (dm)**"
      ],
      "metadata": {
        "id": "ow9GkC1p-b7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Handling NaN values in 'dm' column\n",
        "df['dm'] = df['dm'].fillna(df['dm'].mean())\n",
        "\n",
        "# Selecting 'dm' as the feature and 'class' as the target\n",
        "X = df['dm'].values.reshape(-1,1)\n",
        "y = df['class'].values\n",
        "\n",
        "# Splitting the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "# Initializing the Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "\n",
        "# Training the model\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Printing the confusion matrix and accuracy score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8CL1V3pASdt",
        "outputId": "164340b7-80b2-460e-90d3-9afef3fd0019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[15  0]\n",
            " [15 21]]\n",
            "0.7058823529411765\n"
          ]
        }
      ]
    }
  ]
}